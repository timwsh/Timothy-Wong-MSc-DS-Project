{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1bcd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad00df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import json\n",
    "import torch\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d064c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "###setting directory\n",
    "data_dir=\"data\"\n",
    "model_dir=\"models\"\n",
    "output_dir=\"output\"\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5c706",
   "metadata": {},
   "source": [
    "# Finetune model: load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2138833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change\n",
    "from datasets import Dataset\n",
    "#PVE_input = Dataset.from_pandas(pd.read_csv('data\\PVE_covid_annotation_v0_1.csv', encoding='latin1',index_col=0))\n",
    "PVE_input =pd.read_excel('data\\PVE_covid_annotation_v6_annotated.xlsx', index_col=0)\n",
    "train_set=Dataset.from_pandas(PVE_input[(PVE_input['AL_batch']>=0) & (PVE_input['AL_batch']<=6)])\n",
    "test_set=Dataset.from_pandas(PVE_input[PVE_input['BL_batch']==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2c4153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['opinion', 'project', 'random_order', 'BL_batch', 'AL_batch', 'Autonomy_for_companies', 'Autonomy_for_close_contact_professions', 'Quality_of_life_for_elderly', 'Family_value', 'Feasibility', 'Acceptance_of_exception', 'The_need_of_schooling', 'Working_safety', 'Well-being', 'Reduce_adverse_effect', 'step_0_margin', 'step_0_rank', 'step_1_margin', 'step_1_rank', 'step_2_margin', 'step_2_rank', 'step_3_margin', 'step_3_rank', 'step_4_margin', 'step_4_rank', 'step_5_margin', 'step_5_rank', 'step_6_margin', 'step_6_rank', 'step_7_margin', 'step_7_rank', 'step_8_margin', 'step_8_rank', 'step_9_margin', 'step_9_rank', '__index_level_0__'],\n",
       "    num_rows: 350\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0472546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Autonomy_for_companies',\n",
    " 'Autonomy_for_close_contact_professions',\n",
    " 'Quality_of_life_for_elderly',\n",
    " 'Family_value',\n",
    " 'Feasibility',\n",
    " 'Acceptance_of_exception',\n",
    " 'The_need_of_schooling',\n",
    " 'Working_safety',\n",
    " 'Well-being',\n",
    " 'Reduce_adverse_effect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a06e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "105938d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Autonomy_for_companies': 0,\n",
       " 'Autonomy_for_close_contact_professions': 1,\n",
       " 'Quality_of_life_for_elderly': 2,\n",
       " 'Family_value': 3,\n",
       " 'Feasibility': 4,\n",
       " 'Acceptance_of_exception': 5,\n",
       " 'The_need_of_schooling': 6,\n",
       " 'Working_safety': 7,\n",
       " 'Well-being': 8,\n",
       " 'Reduce_adverse_effect': 9}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da750370",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b309f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    #text = examples[\"Tweet\"]\n",
    "    # encode them\n",
    "    encoding = tokenizer(examples['project'], examples['opinion'], truncation=True)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(examples['opinion']), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c70b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_train_set = train_set.map(preprocess_data, batched=True, remove_columns=train_set.column_names)\n",
    "encoded_test_set = test_set.map(preprocess_data, batched=True, remove_columns=test_set.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff25631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example =encoded_train_set[0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d7c7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] nursing homes allow visitors again [SEP] loneliness in the last phase of life is inhumane and also leads to premature death. [SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b2f1203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf7fda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quality_of_life_for_elderly', 'Well-being']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b36447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX550\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print(f'We will use the GPU: {torch.cuda.get_device_name(0)}')\n",
    "    encoded_train_set.set_format(\"torch\", device='cuda:0')\n",
    "    encoded_test_set.set_format(\"torch\", device='cuda:0')\n",
    "else:\n",
    "    encoded_train_set.set_format(\"torch\")\n",
    "    encoded_test_set.set_format(\"torch\")\n",
    "    print('No GPU available, using the CPU instead.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59de53",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59d28a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./models/bert_train_level1/ and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([54, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([54]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./models/bert_train_level1/' , \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55016543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX550\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print(f'We will use the GPU: {torch.cuda.get_device_name(0)}')\n",
    "    model.to('cuda')\n",
    "else:    \n",
    "    print('No GPU available, using the CPU instead.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eff6e8",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "343f1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "#batch_size = 8\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bce541cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    #evaluation_strategy = \"epoch\",\n",
    "    #save_strategy = \"epoch\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    #learning_rate=2e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    #num_train_epochs=40,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    logging_steps=100,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df99c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b37fbd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_set[0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af3dbe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  8329,  5014,  3499,  5731,  2153,   102, 20334,  1999,  1996,\n",
       "         2197,  4403,  1997,  2166,  2003, 29582,  2063,  1998,  2036,  5260,\n",
       "         2000, 21371,  2331,  1012,   102], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_set['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "827c94e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_set['input_ids'][0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65a6ad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7311, device='cuda:0',\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.3448, -0.1514, -0.8419,  0.0243,  0.4834, -0.6003,  0.0469, -0.7025,\n",
       "         -0.1414,  0.4816]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=encoded_train_set['input_ids'][0].unsqueeze(0), labels=encoded_train_set['labels'][0].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6e7d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_train_set,\n",
    "    eval_dataset=encoded_test_set,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84b56c68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 350\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5250\n",
      "  Number of trainable parameters = 109489930\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5250' max='5250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5250/5250 1:23:19, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.345384</td>\n",
       "      <td>0.366492</td>\n",
       "      <td>0.612530</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.344500</td>\n",
       "      <td>0.293204</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.728782</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.258524</td>\n",
       "      <td>0.600823</td>\n",
       "      <td>0.728039</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>0.246832</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0.772174</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.245567</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.790840</td>\n",
       "      <td>0.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.220850</td>\n",
       "      <td>0.720848</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.195400</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.736134</td>\n",
       "      <td>0.836299</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.202746</td>\n",
       "      <td>0.728546</td>\n",
       "      <td>0.822224</td>\n",
       "      <td>0.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.193404</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.817481</td>\n",
       "      <td>0.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.192344</td>\n",
       "      <td>0.753820</td>\n",
       "      <td>0.843843</td>\n",
       "      <td>0.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.186571</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.837911</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.184962</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.839396</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.185706</td>\n",
       "      <td>0.784053</td>\n",
       "      <td>0.866940</td>\n",
       "      <td>0.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.188018</td>\n",
       "      <td>0.755932</td>\n",
       "      <td>0.845472</td>\n",
       "      <td>0.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.175818</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.859387</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.189207</td>\n",
       "      <td>0.786070</td>\n",
       "      <td>0.868569</td>\n",
       "      <td>0.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.189285</td>\n",
       "      <td>0.777595</td>\n",
       "      <td>0.865463</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.177937</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.862797</td>\n",
       "      <td>0.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.173254</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.866788</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.186587</td>\n",
       "      <td>0.794830</td>\n",
       "      <td>0.881159</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.179694</td>\n",
       "      <td>0.782753</td>\n",
       "      <td>0.866645</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.178522</td>\n",
       "      <td>0.787479</td>\n",
       "      <td>0.871235</td>\n",
       "      <td>0.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.187894</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.877455</td>\n",
       "      <td>0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.186276</td>\n",
       "      <td>0.783471</td>\n",
       "      <td>0.867978</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.185045</td>\n",
       "      <td>0.792013</td>\n",
       "      <td>0.871083</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.189540</td>\n",
       "      <td>0.788871</td>\n",
       "      <td>0.873902</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.867683</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.190575</td>\n",
       "      <td>0.788686</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.193504</td>\n",
       "      <td>0.790774</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.188718</td>\n",
       "      <td>0.790083</td>\n",
       "      <td>0.871826</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.190505</td>\n",
       "      <td>0.790164</td>\n",
       "      <td>0.874197</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.191108</td>\n",
       "      <td>0.788177</td>\n",
       "      <td>0.872569</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.197768</td>\n",
       "      <td>0.792144</td>\n",
       "      <td>0.875826</td>\n",
       "      <td>0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.195914</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.881455</td>\n",
       "      <td>0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.195376</td>\n",
       "      <td>0.789386</td>\n",
       "      <td>0.870493</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.196020</td>\n",
       "      <td>0.794069</td>\n",
       "      <td>0.875083</td>\n",
       "      <td>0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.198757</td>\n",
       "      <td>0.794788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.199577</td>\n",
       "      <td>0.790774</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.197169</td>\n",
       "      <td>0.790774</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.201226</td>\n",
       "      <td>0.792763</td>\n",
       "      <td>0.874788</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.200609</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.874493</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.201472</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.873455</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.200212</td>\n",
       "      <td>0.790774</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.200877</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.872864</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.203560</td>\n",
       "      <td>0.790774</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.201425</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.873455</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.202952</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.873455</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.201427</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.873455</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.202407</td>\n",
       "      <td>0.790774</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.202221</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.873455</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.203061</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.873455</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-500\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-500\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-1000\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-1000\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-1000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-1500\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-1500\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-1500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-2000\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-2000\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-2000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-2500\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-2500\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-2500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-3000\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-3000\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-3000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-3500\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-3500\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-3500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-4000\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-4000\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-4000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-4500\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-4500\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-4500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to bert-finetuned-sem_eval-english\\checkpoint-5000\n",
      "Configuration saved in bert-finetuned-sem_eval-english\\checkpoint-5000\\config.json\n",
      "Model weights saved in bert-finetuned-sem_eval-english\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-sem_eval-english\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-sem_eval-english\\checkpoint-5000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from bert-finetuned-sem_eval-english\\checkpoint-3500 (score: 0.796116504854369).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5250, training_loss=0.06897228411265782, metrics={'train_runtime': 5000.5386, 'train_samples_per_second': 2.1, 'train_steps_per_second': 1.05, 'total_flos': 415258126244304.0, 'train_loss': 0.06897228411265782, 'epoch': 30.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9aa0dc",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0d50392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1959141492843628,\n",
       " 'eval_f1': 0.796116504854369,\n",
       " 'eval_roc_auc': 0.8814547735357893,\n",
       " 'eval_accuracy': 0.515,\n",
       " 'eval_runtime': 7.7635,\n",
       " 'eval_samples_per_second': 25.761,\n",
       " 'eval_steps_per_second': 12.881,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc88947",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4cd0bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200\n",
      "  Batch size = 2\n"
     ]
    }
   ],
   "source": [
    "test_pred=trainer.predict(encoded_test_set).predictions\n",
    "test_pred = torch.from_numpy(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0a87e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    67\n",
       "1    41\n",
       "2    22\n",
       "3    23\n",
       "4     7\n",
       "5    42\n",
       "6     6\n",
       "7     4\n",
       "8    70\n",
       "9    29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(1*(test_pred.sigmoid()>0.5)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef711a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        64\n",
      "           1       0.95      0.95      0.95        41\n",
      "           2       0.77      0.81      0.79        21\n",
      "           3       0.57      0.93      0.70        14\n",
      "           4       0.71      0.36      0.48        14\n",
      "           5       0.57      0.73      0.64        33\n",
      "           6       0.67      1.00      0.80         4\n",
      "           7       1.00      0.25      0.40        16\n",
      "           8       0.79      0.82      0.80        67\n",
      "           9       0.83      0.73      0.77        33\n",
      "\n",
      "   micro avg       0.79      0.80      0.80       307\n",
      "   macro avg       0.78      0.75      0.73       307\n",
      "weighted avg       0.81      0.80      0.79       307\n",
      " samples avg       0.75      0.74      0.72       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report\n",
    "\n",
    "print(classification_report(PVE_input[PVE_input['BL_batch']==-1].iloc[:, 5:15],np.matrix(1*(test_pred.sigmoid()>0.5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "524f1f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[130,   6],\n",
       "        [  3,  61]],\n",
       "\n",
       "       [[157,   2],\n",
       "        [  2,  39]],\n",
       "\n",
       "       [[174,   5],\n",
       "        [  4,  17]],\n",
       "\n",
       "       [[176,  10],\n",
       "        [  1,  13]],\n",
       "\n",
       "       [[184,   2],\n",
       "        [  9,   5]],\n",
       "\n",
       "       [[149,  18],\n",
       "        [  9,  24]],\n",
       "\n",
       "       [[194,   2],\n",
       "        [  0,   4]],\n",
       "\n",
       "       [[184,   0],\n",
       "        [ 12,   4]],\n",
       "\n",
       "       [[118,  15],\n",
       "        [ 12,  55]],\n",
       "\n",
       "       [[162,   5],\n",
       "        [  9,  24]]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(PVE_input[PVE_input['BL_batch']==-1].iloc[:, 5:15],np.matrix(1*(test_pred.sigmoid()>0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e73a9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in models\\config.json\n",
      "Model weights saved in models\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ab1c6",
   "metadata": {},
   "source": [
    "# Select cases for active sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99aff60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PVE_input_selection=PVE_input[np.isnan(PVE_input['AL_batch'])]\n",
    "selection_set=Dataset.from_pandas(PVE_input_selection)\n",
    "#selection_set=Dataset.from_pandas(PVE_input[np.isnan(PVE_input['AL_batch'])][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c5fbe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['opinion', 'project', 'random_order', 'BL_batch', 'AL_batch', 'Autonomy_for_companies', 'Autonomy_for_close_contact_professions', 'Quality_of_life_for_elderly', 'Family_value', 'Feasibility', 'Acceptance_of_exception', 'The_need_of_schooling', 'Working_safety', 'Well-being', 'Reduce_adverse_effect', 'step_0_margin', 'step_0_rank', 'step_1_margin', 'step_1_rank', 'step_2_margin', 'step_2_rank', 'step_3_margin', 'step_3_rank', 'step_4_margin', 'step_4_rank', 'step_5_margin', 'step_5_rank', 'step_6_margin', 'step_6_rank', 'step_7_margin', 'step_7_rank', 'step_8_margin', 'step_8_rank', 'step_9_margin', 'step_9_rank', '__index_level_0__'],\n",
       "    num_rows: 58911\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9cfdcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_selection_set = selection_set.map(preprocess_data, batched=True, remove_columns=selection_set.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6c886e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX550\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print(f'We will use the GPU: {torch.cuda.get_device_name(0)}')\n",
    "    encoded_selection_set.set_format(\"torch\", device='cuda:0')\n",
    "else:\n",
    "    encoded_selection_set.set_format(\"torch\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b40941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_selection_set=encoded_selection_set.remove_columns(['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6edd82e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 58911\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selection_pred=trainer.predict(encoded_selection_set).predictions\n",
    "selection_pred = torch.from_numpy(selection_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f0d6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(1*(selection_pred.sigmoid()>0.5)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8aab4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(abs(selection_pred.sigmoid()-0.5)).min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a8dfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(abs(selection_pred.sigmoid()-0.5)).min(axis=1).rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e57e0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "PVE_input_selection['margin']=list(pd.DataFrame(abs(selection_pred.sigmoid()-0.5)).min(axis=1))\n",
    "PVE_input_selection['margin_rank']=list(pd.DataFrame(abs(selection_pred.sigmoid()-0.5)).min(axis=1).rank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c638d817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PVE_input_selection.to_excel('selected_case.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd656b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=pd.DataFrame(selection_pred.sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ed62a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.to_excel('selected_case_prob.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b588f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
