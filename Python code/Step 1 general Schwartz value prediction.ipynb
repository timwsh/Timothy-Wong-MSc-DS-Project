{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1bcd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad00df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from transformers import AutoModel # For BERTs\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d064c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "###setting directory\n",
    "data_dir=\"data\"\n",
    "model_dir=\"models\"\n",
    "output_dir=\"output\"\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a722af",
   "metadata": {},
   "source": [
    "# Read general value list (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "042c706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the classes in the model\n",
    "def load_values_from_json(filepath):\n",
    "    \"\"\"Load values per level from json-file from `filepath`\"\"\"\n",
    "    json_values = load_json_file(filepath)\n",
    "    #values = set() \n",
    "    values = []\n",
    "    for value in json_values[\"values\"]:\n",
    "        #values.add(value[\"level2\"])\n",
    "        values.append(value[\"name\"])\n",
    "    #values= sorted(values)\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213c6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json file of classes in the model\n",
    "def load_json_file(filepath):\n",
    "    \"\"\"Load content of json-file from `filepath`\"\"\"\n",
    "    with open(filepath, 'r') as  json_file:\n",
    "        return json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b1cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of values to be predicted, and their length\n",
    "values_filepath = os.path.join(data_dir, 'values.json')\n",
    "values = load_values_from_json(values_filepath)\n",
    "#print(values)\n",
    "num_labels = len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eef83ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Be creative',\n",
       " 'Be curious',\n",
       " 'Have freedom of thought',\n",
       " 'Be choosing own goals',\n",
       " 'Be independent',\n",
       " 'Have freedom of action',\n",
       " 'Have privacy',\n",
       " 'Have an exciting life',\n",
       " 'Have a varied life',\n",
       " 'Be daring',\n",
       " 'Have pleasure',\n",
       " 'Be ambitious',\n",
       " 'Have success',\n",
       " 'Be capable',\n",
       " 'Be intellectual',\n",
       " 'Be courageous',\n",
       " 'Have influence',\n",
       " 'Have the right to command',\n",
       " 'Have wealth',\n",
       " 'Have social recognition',\n",
       " 'Have a good reputation',\n",
       " 'Have a sense of belonging',\n",
       " 'Have good health',\n",
       " 'Have no debts',\n",
       " 'Be neat and tidy',\n",
       " 'Have a comfortable life',\n",
       " 'Have a safe country',\n",
       " 'Have a stable society',\n",
       " 'Be respecting traditions',\n",
       " 'Be holding religious faith',\n",
       " 'Be compliant',\n",
       " 'Be self-disciplined',\n",
       " 'Be behaving properly',\n",
       " 'Be polite',\n",
       " 'Be honoring elders',\n",
       " 'Be humble',\n",
       " 'Have life accepted as is',\n",
       " 'Be helpful',\n",
       " 'Be honest',\n",
       " 'Be forgiving',\n",
       " 'Have the own family secured',\n",
       " 'Be loving',\n",
       " 'Be responsible',\n",
       " 'Have loyalty towards friends',\n",
       " 'Have equality',\n",
       " 'Be just',\n",
       " 'Have a world at peace',\n",
       " 'Be protecting the environment',\n",
       " 'Have harmony with nature',\n",
       " 'Have a world of beauty',\n",
       " 'Be broadminded',\n",
       " 'Have the wisdom to accept others',\n",
       " 'Be logical',\n",
       " 'Have an objective view']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5c706",
   "metadata": {},
   "source": [
    "# Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b309f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce541cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "def load_model_from_data_dir(model_dir, num_labels):\n",
    "    \"\"\"Loads Bert model from specified directory and converts to CUDA model if available\"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir, \n",
    "    num_labels=num_labels,\n",
    ")\n",
    "\n",
    "    \n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "        print(f'We will use the GPU: {torch.cuda.get_device_name(0)}')\n",
    "        return model.to('cuda')\n",
    "    \n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "990c7f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def predict_nn(trained_model, test_dataset):\n",
    "\n",
    "    # Switch off dropout\n",
    "    trained_model.eval()\n",
    "    \n",
    "    # Pass the required items from the dataset to the model    \n",
    "    output = trained_model(attention_mask=torch.tensor(test_dataset[\"attention_mask\"]), input_ids=torch.tensor(test_dataset[\"input_ids\"]))\n",
    "    #output = trained_model(attention_mask=test_dataset[\"attention_mask\"], input_ids=test_dataset[\"input_ids\"])    \n",
    "                        \n",
    "    # the output dictionary contains logits, which are the unnormalised scores for each class for each example:\n",
    "    pred_labs = np.argmax(output[\"logits\"].detach().numpy(), axis=1)\n",
    "\n",
    "    return pred_labs\n",
    "'''\n",
    "\n",
    "from transformers import Trainer\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    \"\"\"\n",
    "        A transformers `Trainer` with custom loss computation\n",
    "\n",
    "        Methods\n",
    "        -------\n",
    "        compute_loss(model, inputs, return_outputs=False):\n",
    "            Overrides loss computation from Trainer class\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"Custom loss computation\"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n",
    "                        labels.float().view(-1, self.model.config.num_labels))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb4726",
   "metadata": {},
   "source": [
    "# prepare data for prediction (covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490156ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('data\\corona_motivations.yaml', 'r') as file:\n",
    "    PVE_covid_yaml = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9bbf20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['english', 'dutch', 'project'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PVE_covid_yaml.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0231e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PVE_covid=pd.DataFrame()\n",
    "PVE_covid['opinion']=PVE_covid_yaml['english']\n",
    "PVE_covid['project']=''\n",
    "PVE_covid['project'][pd.Series(PVE_covid_yaml['project'])==1]='Nursing homes allow visitors again'\n",
    "PVE_covid['project'][pd.Series(PVE_covid_yaml['project'])==2]='Reopen companies (horeca and contact professions are still closed)'\n",
    "PVE_covid['project'][pd.Series(PVE_covid_yaml['project'])==3]='Workers in contact professions can work again'\n",
    "PVE_covid['project'][pd.Series(PVE_covid_yaml['project'])==4]='Young people do not need to maintain 1.5 meter distance among each others'\n",
    "PVE_covid['project'][pd.Series(PVE_covid_yaml['project'])==5]='All restrictions are lifted for persons who are immune'\n",
    "PVE_covid['project'][pd.Series(PVE_covid_yaml['project'])==6]='Restrictions are lifted in Friesland, Groningen and Drenthe'\n",
    "PVE_covid['project'][pd.Series(PVE_covid_yaml['project'])==7]='Direct family members do not need to maintain 1.5 meter distance'\n",
    "PVE_covid['project'][pd.Series(PVE_covid_yaml['project'])==8]='Horeca and entertainment re-open'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583bd19",
   "metadata": {},
   "source": [
    "# Input for Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34f6c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tokenizer used\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#use tokenizer of \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef708c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change\n",
    "PVE_input = Dataset.from_pandas(PVE_covid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14344582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['opinion', 'project'],\n",
       "    num_rows: 59461\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PVE_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0973ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define tokenize_function\n",
    "def tokenize_function(dataset):\n",
    "    # Pass two strings to the tokenizer -- it will concatenate them with a [SEP] special token between them. \n",
    "    model_inputs = tokenizer(dataset['opinion'], dataset['project'], padding=\"max_length\", max_length=200, truncation='longest_first')\n",
    "    #model_inputs = tokenizer(dataset['opinion'], padding=\"max_length\", max_length=200, truncation='longest_first')\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14dd9d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/59461 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add tokenized words, \"attention_mask\" and \"input_ids\" into the datasets\n",
    "PVE_input = PVE_input.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "680afccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['opinion', 'project', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 59461\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PVE_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c482a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting arguments\n",
    "from transformers import TrainingArguments\n",
    "batch_size = 8\n",
    "args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    do_train=False,\n",
    "    do_eval=False,\n",
    "    do_predict=True,\n",
    "    per_device_eval_batch_size=batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "896311f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX550\n"
     ]
    }
   ],
   "source": [
    "#load pretrained model\n",
    "model = load_model_from_data_dir('./models/bert_train_level1/' , num_labels=len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3228a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    \"\"\"\n",
    "        A transformers `Trainer` with custom loss computation\n",
    "\n",
    "        Methods\n",
    "        -------\n",
    "        compute_loss(model, inputs, return_outputs=False):\n",
    "            Overrides loss computation from Trainer class\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"Custom loss computation\"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n",
    "                        labels.float().view(-1, self.model.config.num_labels))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ee8449e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: project, opinion. If project, opinion are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 59461\n",
      "  Batch size = 8\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5224.204123258591"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do projection\n",
    "startTime = time.time()\n",
    "multi_trainer = MultiLabelTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "prediction = 1 * (multi_trainer.predict(PVE_input ).predictions > 0.5)\n",
    "time.time()-startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a27f5983",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_covid=pd.concat([PVE_covid,pd.DataFrame(prediction, columns=values)], axis=1)\n",
    "result_covid.to_csv(os.path.join(output_dir, 'result_covid.csv'),index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8e606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
